# =============================================================================
# ğŸ“Š å®æˆ˜ä¸€ï¼šç”µä¿¡å®¢æˆ·æµå¤±é¢„æµ‹ - ä»æ•°æ®åˆ°æ¨¡å‹çš„å®Œæ•´å®è·µ
# ä½œè€…ï¼šæ¸Šé±¼986 | é€‚åˆï¼šæœºå™¨å­¦ä¹ åˆå­¦è€…åˆ°è¿›é˜¶
# =============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
from sklearn.pipeline import Pipeline
from imblearn.combine import SMOTEENN
import warnings
warnings.filterwarnings('ignore')

# 1ï¸âƒ£ ç»Ÿä¸€ seaborn æ ·å¼
sns.set_style('whitegrid')

# 2ï¸âƒ£ æŒ‡å®šå­—ä½“ï¼ˆæ ¹æ®å®é™…è·¯å¾„è°ƒæ•´ï¼‰
yahei_regular = r"C:\Windows\Fonts\msyh.ttc"
yahei_bold    = r"C:\Windows\Fonts\msyhbd.ttc"

plt.rcParams.update({
    'font.family'      : 'sans-serif',
    'font.sans-serif'  : ['Microsoft YaHei', 'SimHei', 'Arial'],
    'axes.unicode_minus': False,          # è§£å†³è´Ÿå·
    'font.weight'      : 'regular',       # é»˜è®¤ä¸ç”¨ç²—ä½“ï¼Œé¿å…é€€å›
})

print("ğŸ¯ æ¬¢è¿æ¥åˆ°ç”µä¿¡å®¢æˆ·æµå¤±é¢„æµ‹å®æˆ˜ï¼")
print("ğŸ“š æœ¬æ•™ç¨‹å°†å¸¦ä½ ä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªå®Œæ•´çš„åˆ†ç±»æ¨¡å‹")

# =============================================================================
# ğŸ“– ç¬¬ä¸€æ­¥ï¼šæ•°æ®åŠ è½½ä¸åˆæ­¥æ¢ç´¢
# =============================================================================

print("=" * 60)
print("ğŸ” æ­¥éª¤1ï¼šåŠ è½½æ•°æ®é›†")
print("=" * 60)

# åŠ è½½æ•°æ®
data = pd.read_csv(r"archive\WA_Fn-UseC_-Telco-Customer-Churn.csv")

print(f"ğŸ“Š æ•°æ®é›†åŸºæœ¬ä¿¡æ¯ï¼š")
print(f"   - æ ·æœ¬æ•°é‡ï¼š{data.shape[0]:,} æ¡")
print(f"   - ç‰¹å¾æ•°é‡ï¼š{data.shape[1]} ä¸ª")
print(f"   - å†…å­˜å ç”¨ï¼š{data.memory_usage(deep=True).sum() / 1024**2:.2f} MB")

# æ˜¾ç¤ºå‰5è¡Œæ•°æ®
print("\nğŸ“‹ æ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰ï¼š")
print(data.head())

# æ•°æ®ç±»å‹åˆ†æ
print("\nğŸ” æ•°æ®ç±»å‹åˆ†æï¼š")
print(data.dtypes.value_counts())

# =============================================================================
# ğŸ“Š ç¬¬äºŒæ­¥ï¼šæ·±åº¦æ•°æ®æ¢ç´¢ï¼ˆEDAï¼‰
# =============================================================================

print("=" * 60)
print("ğŸ“ˆ æ­¥éª¤2ï¼šæ¢ç´¢æ€§æ•°æ®åˆ†æï¼ˆEDAï¼‰")
print("=" * 60)

# ç›®æ ‡å˜é‡åˆ†å¸ƒåˆ†æ
def analyze_target_distribution(data):
    """åˆ†æç›®æ ‡å˜é‡çš„åˆ†å¸ƒæƒ…å†µ"""
    churn_counts = data['Churn'].value_counts()
    churn_pct = data['Churn'].value_counts(normalize=True) * 100
    
    print("ğŸ¯ ç›®æ ‡å˜é‡åˆ†å¸ƒï¼š")
    print(f"   - æœªæµå¤±å®¢æˆ·ï¼š{churn_counts['No']:,} äºº ({churn_pct['No']:.1f}%)")
    print(f"   - æµå¤±å®¢æˆ·ï¼š{churn_counts['Yes']:,} äºº ({churn_pct['Yes']:.1f}%)")
    print(f"   - ç±»åˆ«ä¸å¹³è¡¡æ¯”ä¾‹ï¼š1:{churn_counts['No']/churn_counts['Yes']:.1f}")
    
    # ç»˜åˆ¶åˆ†å¸ƒå›¾
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # é¥¼å›¾
    colors = ['#ff9999', '#66b3ff']
    ax1.pie(churn_counts.values, labels=['æœªæµå¤±', 'æµå¤±'], autopct='%1.1f%%', 
            colors=colors, startangle=90)
    ax1.set_title('å®¢æˆ·æµå¤±åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    
    # æŸ±çŠ¶å›¾
    bars = ax2.bar(['æœªæµå¤±', 'æµå¤±'], churn_counts.values, color=colors)
    ax2.set_title('å®¢æˆ·æµå¤±æ•°é‡å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax2.set_ylabel('å®¢æˆ·æ•°é‡')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, count in zip(bars, churn_counts.values):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,
                f'{count:,}', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.show()

analyze_target_distribution(data)

# =============================================================================
# ğŸ”§ ç¬¬ä¸‰æ­¥ï¼šæ•°æ®é¢„å¤„ç† - ç‰¹å¾å·¥ç¨‹çš„è‰ºæœ¯
# =============================================================================

print("=" * 60)
print("âš™ï¸ æ­¥éª¤3ï¼šæ•°æ®é¢„å¤„ç†ä¸ç‰¹å¾å·¥ç¨‹")
print("=" * 60)

# åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡å˜é‡
print("ğŸ¯ åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡å˜é‡...")
X = data.drop(['customerID', 'Churn'], axis=1)
y = data['Churn'].map({'No': 0, 'Yes': 1})

print(f"   âœ… ç‰¹å¾çŸ©é˜µ X: {X.shape}")
print(f"   âœ… ç›®æ ‡å˜é‡ y: {y.shape}")

# æ£€æŸ¥ç¼ºå¤±å€¼
print("\nğŸ” ç¼ºå¤±å€¼æ£€æŸ¥ï¼š")
missing_info = X.isnull().sum()
if missing_info.sum() == 0:
    print("   âœ… å¤ªæ£’äº†ï¼æ²¡æœ‰å‘ç°ç¼ºå¤±å€¼")
else:
    print("   âš ï¸ å‘ç°ç¼ºå¤±å€¼ï¼š")
    print(missing_info[missing_info > 0])

# ç‰¹å¾ç±»å‹åˆ†æ
num_cols = X.select_dtypes(include=['float', 'int']).columns.tolist()
cat_cols = X.select_dtypes(include=['object']).columns.tolist()

print(f"\nğŸ“Š ç‰¹å¾ç±»å‹ç»Ÿè®¡ï¼š")
print(f"   - æ•°å€¼å‹ç‰¹å¾ï¼š{len(num_cols)} ä¸ª {num_cols}")
print(f"   - ç±»åˆ«å‹ç‰¹å¾ï¼š{len(cat_cols)} ä¸ª {cat_cols}")

# æ•°å€¼ç‰¹å¾æ ‡å‡†åŒ–
print("\nğŸ”„ æ•°å€¼ç‰¹å¾æ ‡å‡†åŒ–å¤„ç†...")
scaler = StandardScaler()
X_num_scaled = pd.DataFrame(
    scaler.fit_transform(X[num_cols]), 
    columns=num_cols, 
    index=X.index
)

print(f"   âœ… æ ‡å‡†åŒ–å‰åå¯¹æ¯”ï¼ˆä»¥MonthlyChargesä¸ºä¾‹ï¼‰ï¼š")
print(f"      åŸå§‹æ•°æ®ï¼šå‡å€¼={X['MonthlyCharges'].mean():.2f}, æ ‡å‡†å·®={X['MonthlyCharges'].std():.2f}")
print(f"      æ ‡å‡†åŒ–åï¼šå‡å€¼={X_num_scaled['MonthlyCharges'].mean():.2f}, æ ‡å‡†å·®={X_num_scaled['MonthlyCharges'].std():.2f}")

# ç±»åˆ«ç‰¹å¾ç‹¬çƒ­ç¼–ç 
print("\nğŸ”„ ç±»åˆ«ç‰¹å¾ç‹¬çƒ­ç¼–ç å¤„ç†...")
ohe = OneHotEncoder(sparse_output=False, drop='first')  # drop='first'é¿å…å¤šé‡å…±çº¿æ€§
X_cat_encoded = ohe.fit_transform(X[cat_cols])

# è·å–ç¼–ç åçš„ç‰¹å¾å
feature_names = ohe.get_feature_names_out(cat_cols)
X_cat_encoded = pd.DataFrame(X_cat_encoded, columns=feature_names, index=X.index)

print(f"   âœ… ç¼–ç å‰ï¼š{len(cat_cols)} ä¸ªç±»åˆ«ç‰¹å¾")
print(f"   âœ… ç¼–ç åï¼š{X_cat_encoded.shape[1]} ä¸ªäºŒè¿›åˆ¶ç‰¹å¾")

# åˆå¹¶æ‰€æœ‰ç‰¹å¾
X_processed = pd.concat([X_num_scaled, X_cat_encoded], axis=1)
print(f"\nğŸ‰ ç‰¹å¾å·¥ç¨‹å®Œæˆï¼æœ€ç»ˆç‰¹å¾çŸ©é˜µï¼š{X_processed.shape}")

# =============================================================================
# ğŸ¤– ç¬¬å››æ­¥ï¼šæ¨¡å‹è®­ç»ƒä¸å¯¹æ¯” - ä¸‰å¤§ç»å…¸ç®—æ³•PK
# =============================================================================

print("=" * 60)
print("ğŸš€ æ­¥éª¤4ï¼šæ¨¡å‹è®­ç»ƒä¸æ€§èƒ½å¯¹æ¯”")
print("=" * 60)

# æ•°æ®é›†åˆ’åˆ†
print("ğŸ“Š åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†...")
X_train, X_test, y_train, y_test = train_test_split(
    X_processed, y, 
    test_size=0.2, 
    stratify=y, 
    random_state=42
)

print(f"   âœ… è®­ç»ƒé›†ï¼š{X_train.shape[0]:,} æ ·æœ¬")
print(f"   âœ… æµ‹è¯•é›†ï¼š{X_test.shape[0]:,} æ ·æœ¬")
print(f"   âœ… è®­ç»ƒé›†æµå¤±ç‡ï¼š{y_train.mean():.1%}")
print(f"   âœ… æµ‹è¯•é›†æµå¤±ç‡ï¼š{y_test.mean():.1%}")

# å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
print("\nâš–ï¸ ä½¿ç”¨SMOTEENNå¤„ç†ç±»åˆ«ä¸å¹³è¡¡...")
smoteenn = SMOTEENN(random_state=42)
X_resampled, y_resampled = smoteenn.fit_resample(X_train, y_train)

print(f"   ğŸ“ˆ é‡é‡‡æ ·å‰ï¼š{X_train.shape[0]:,} æ ·æœ¬ï¼Œæµå¤±ç‡ {y_train.mean():.1%}")
print(f"   ğŸ“ˆ é‡é‡‡æ ·åï¼š{X_resampled.shape[0]:,} æ ·æœ¬ï¼Œæµå¤±ç‡ {y_resampled.mean():.1%}")

# å®šä¹‰æ¨¡å‹å­—å…¸
models = {
    'é€»è¾‘å›å½’': LogisticRegression(random_state=42, max_iter=1000),
    'éšæœºæ£®æ—': RandomForestClassifier(n_estimators=100, random_state=42),
    'æ”¯æŒå‘é‡æœº': SVC(kernel='linear', C=0.025, probability=True, random_state=42)
}

print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ {len(models)} ä¸ªæ¨¡å‹...")

# æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°
results = {}

for name, model in models.items():
    print(f"\n{'='*50}")
    print(f"ğŸ”¥ æ­£åœ¨è®­ç»ƒï¼š{name}")
    print(f"{'='*50}")
    
    # è®­ç»ƒæ¨¡å‹
    model.fit(X_resampled, y_resampled)
    
    # é¢„æµ‹
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    
    # è®¡ç®—æŒ‡æ ‡
    auc_score = roc_auc_score(y_test, y_pred_proba)
    
    # ä¿å­˜ç»“æœ
    results[name] = {
        'model': model,
        'y_pred': y_pred,
        'y_pred_proba': y_pred_proba,
        'auc_score': auc_score
    }
    
    # æ‰“å°è¯¦ç»†æŠ¥å‘Š
    print(f"ğŸ“Š {name} æ€§èƒ½æŠ¥å‘Šï¼š")
    print(classification_report(y_test, y_pred, target_names=['æœªæµå¤±', 'æµå¤±']))
    print(f"ğŸ¯ AUC-ROCå¾—åˆ†: {auc_score:.4f}")
    
    # æ··æ·†çŸ©é˜µå¯è§†åŒ–
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['æœªæµå¤±', 'æµå¤±'], 
                yticklabels=['æœªæµå¤±', 'æµå¤±'])
    plt.title(f'{name} - æ··æ·†çŸ©é˜µ', fontsize=14, fontweight='bold')
    plt.ylabel('çœŸå®æ ‡ç­¾')
    plt.xlabel('é¢„æµ‹æ ‡ç­¾')
    plt.tight_layout()
    plt.show()

# =============================================================================
# ğŸ“ˆ ç¬¬äº”æ­¥ï¼šæ¨¡å‹æ€§èƒ½å¯¹æ¯”ä¸å¯è§†åŒ–
# =============================================================================

print("=" * 60)
print("ğŸ“Š æ­¥éª¤5ï¼šæ¨¡å‹æ€§èƒ½ç»¼åˆå¯¹æ¯”")
print("=" * 60)

# æ€§èƒ½å¯¹æ¯”è¡¨æ ¼
performance_df = pd.DataFrame({
    'æ¨¡å‹': list(results.keys()),
    'AUC-ROC': [results[name]['auc_score'] for name in results.keys()]
})

# æ·»åŠ å…¶ä»–æŒ‡æ ‡
for name in results.keys():
    y_pred = results[name]['y_pred']
    report = classification_report(y_test, y_pred, output_dict=True)
    
    performance_df.loc[performance_df['æ¨¡å‹'] == name, 'Precision'] = report['1']['precision']
    performance_df.loc[performance_df['æ¨¡å‹'] == name, 'Recall'] = report['1']['recall']
    performance_df.loc[performance_df['æ¨¡å‹'] == name, 'F1-Score'] = report['1']['f1-score']

# æŒ‰AUCæ’åº
performance_df = performance_df.sort_values('AUC-ROC', ascending=False)

print("ğŸ† æ¨¡å‹æ€§èƒ½æ’è¡Œæ¦œï¼š")
print(performance_df.round(4))

# å¯è§†åŒ–å¯¹æ¯”
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# AUCå¯¹æ¯”
axes[0,0].bar(performance_df['æ¨¡å‹'], performance_df['AUC-ROC'], 
              color=['gold', 'silver', '#CD7F32'])
axes[0,0].set_title('AUC-ROC å¯¹æ¯”', fontweight='bold')
axes[0,0].set_ylabel('AUC-ROC')
axes[0,0].set_ylim(0.7, 0.9)

# Precisionå¯¹æ¯”
axes[0,1].bar(performance_df['æ¨¡å‹'], performance_df['Precision'], 
              color=['lightcoral', 'lightblue', 'lightgreen'])
axes[0,1].set_title('Precision å¯¹æ¯”', fontweight='bold')
axes[0,1].set_ylabel('Precision')

# Recallå¯¹æ¯”
axes[1,0].bar(performance_df['æ¨¡å‹'], performance_df['Recall'], 
              color=['orange', 'purple', 'brown'])
axes[1,0].set_title('Recall å¯¹æ¯”', fontweight='bold')
axes[1,0].set_ylabel('Recall')

# F1-Scoreå¯¹æ¯”
axes[1,1].bar(performance_df['æ¨¡å‹'], performance_df['F1-Score'], 
              color=['pink', 'cyan', 'yellow'])
axes[1,1].set_title('F1-Score å¯¹æ¯”', fontweight='bold')
axes[1,1].set_ylabel('F1-Score')

plt.tight_layout()
plt.show()

# æ‰¾å‡ºæœ€ä½³æ¨¡å‹
best_model_name = performance_df.iloc[0]['æ¨¡å‹']
best_auc = performance_df.iloc[0]['AUC-ROC']

print(f"\nğŸ‰ æœ€ä½³æ¨¡å‹ï¼š{best_model_name}")
print(f"ğŸ† æœ€é«˜AUCå¾—åˆ†ï¼š{best_auc:.4f}")

# =============================================================================
# ğŸ’¡ ç¬¬å…­æ­¥ï¼šæ€»ç»“ä¸å®æˆ˜å»ºè®®
# =============================================================================

print("=" * 60)
print("ğŸ“ å®æˆ˜æ€»ç»“ä¸ç»éªŒåˆ†äº«")
print("=" * 60)

print("ğŸ“š æœ¬æ¬¡å®æˆ˜æˆ‘ä»¬å­¦åˆ°äº†ä»€ä¹ˆï¼š")
print("   1ï¸âƒ£ æ•°æ®æ¢ç´¢ï¼šé€šè¿‡EDAå‘ç°æ•°æ®ç‰¹ç‚¹å’Œæ½œåœ¨é—®é¢˜")
print("   2ï¸âƒ£ ç‰¹å¾å·¥ç¨‹ï¼šæ•°å€¼æ ‡å‡†åŒ– + ç±»åˆ«ç¼–ç çš„æ ‡å‡†æµç¨‹")
print("   3ï¸âƒ£ ä¸å¹³è¡¡å¤„ç†ï¼šSMOTEENNæ··åˆé‡‡æ ·æŠ€æœ¯çš„åº”ç”¨")
print("   4ï¸âƒ£ æ¨¡å‹å¯¹æ¯”ï¼šä¸‰ç§ç»å…¸ç®—æ³•çš„ä¼˜ç¼ºç‚¹å¯¹æ¯”")
print("   5ï¸âƒ£ æ€§èƒ½è¯„ä¼°ï¼šå¤šæŒ‡æ ‡ç»¼åˆè¯„ä¼°æ¨¡å‹æ€§èƒ½")

print(f"\nğŸ” å…³é”®å‘ç°ï¼š")
print(f"   â€¢ æ•°æ®é›†å­˜åœ¨æ˜æ˜¾çš„ç±»åˆ«ä¸å¹³è¡¡ï¼ˆæµå¤±ç‡çº¦26%ï¼‰")
print(f"   â€¢ SMOTEENNé‡‡æ ·æœ‰æ•ˆæå‡äº†æ¨¡å‹çš„å¬å›ç‡")
print(f"   â€¢ {best_model_name}åœ¨ç»¼åˆæ€§èƒ½ä¸Šè¡¨ç°æœ€ä½³")

print(f"\nğŸ’¼ ä¸šåŠ¡å»ºè®®ï¼š")
print(f"   â€¢ é‡ç‚¹å…³æ³¨æœˆè´¹è¾ƒé«˜çš„æŒ‰æœˆä»˜è´¹å®¢æˆ·")
print(f"   â€¢ å¯¹æ–°å®¢æˆ·ï¼ˆtenureè¾ƒçŸ­ï¼‰åŠ å¼ºå…³æ€€")
print(f"   â€¢ ä¼˜åŒ–åˆåŒæ¡æ¬¾ï¼Œå‡å°‘æŒ‰æœˆä»˜è´¹æ¯”ä¾‹")

print(f"\nğŸš€ ä¸‹ä¸€æ­¥ä¼˜åŒ–æ–¹å‘ï¼š")
print(f"   â€¢ å°è¯•XGBoostã€LightGBMç­‰é›†æˆå­¦ä¹ ç®—æ³•")
print(f"   â€¢ ä½¿ç”¨ç½‘æ ¼æœç´¢æˆ–è´å¶æ–¯ä¼˜åŒ–è°ƒå‚")
print(f"   â€¢ æ·»åŠ SHAPè§£é‡Šæ€§åˆ†æ")
print(f"   â€¢ è€ƒè™‘æˆæœ¬æ•æ„Ÿå­¦ä¹ ")

print(f"\nğŸ¯ æ„Ÿè°¢é˜…è¯»ï¼å¦‚æœè§‰å¾—æœ‰ç”¨ï¼Œè¯·ç‚¹èµæ”¶è—æ”¯æŒï¼")