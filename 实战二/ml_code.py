# =============================================================================
# ğŸ“Š å®æˆ˜äºŒï¼šä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹ - åº”å¯¹æç«¯ä¸å¹³è¡¡æ•°æ®
# ä½œè€…ï¼šæ¸Šé±¼986 | é€‚åˆï¼šæœºå™¨å­¦ä¹ è¿›é˜¶è€…
# =============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier
from sklearn.ensemble import IsolationForest
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, average_precision_score, precision_recall_curve
import warnings
import os
warnings.filterwarnings('ignore')

# 1ï¸âƒ£ ç»Ÿä¸€ seaborn æ ·å¼
sns.set_style('whitegrid')

# 2ï¸âƒ£ æŒ‡å®šå­—ä½“ï¼ˆæ ¹æ®å®é™…è·¯å¾„è°ƒæ•´ï¼‰
plt.rcParams['font.sans-serif'] = ['SimHei'] # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['axes.unicode_minus'] = False # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

print("ğŸ¯ æ¬¢è¿æ¥åˆ°ä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹å®æˆ˜ï¼")
print("ğŸ”¥ æœ¬é¡¹ç›®å°†æŒ‘æˆ˜æç«¯ä¸å¹³è¡¡æ•°æ®ä¸‹çš„åˆ†ç±»é—®é¢˜ã€‚")

# =============================================================================
# ğŸ“– ç¬¬ä¸€æ­¥ï¼šæ•°æ®åŠ è½½ä¸åˆæ­¥æ¢ç´¢
# =============================================================================

print("=" * 60)
print("ğŸ” æ­¥éª¤1ï¼šåŠ è½½æ•°æ®é›†")
print("=" * 60)

# åŠ è½½æ•°æ®
try:
    data = pd.read_csv(r"data/creditcard.csv")
except FileNotFoundError:
    print("é”™è¯¯ï¼šæ‰¾ä¸åˆ° data/creditcard.csv æ–‡ä»¶ã€‚")
    print("è¯·å…ˆä» Kaggle ä¸‹è½½æ•°æ®é›†å¹¶æ”¾åˆ° 'data' ç›®å½•ä¸‹ï¼š")
    print("https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud")
    exit()

print(f"ğŸ“Š æ•°æ®é›†åŸºæœ¬ä¿¡æ¯ï¼š")
print(f"   - æ ·æœ¬æ•°é‡ï¼š{data.shape[0]:,} æ¡")
print(f"   - ç‰¹å¾æ•°é‡ï¼š{data.shape[1]} ä¸ª")

# ç›®æ ‡å˜é‡åˆ†å¸ƒåˆ†æ
fraud_counts = data['Class'].value_counts()
fraud_pct = data['Class'].value_counts(normalize=True) * 100

print("\nğŸ¯ ç›®æ ‡å˜é‡åˆ†å¸ƒï¼š")
print(f"   - æ­£å¸¸äº¤æ˜“ï¼š{fraud_counts[0]:,} ç¬” ({fraud_pct[0]:.3f}%)")
print(f"   - æ¬ºè¯ˆäº¤æ˜“ï¼š{fraud_counts[1]:,} ç¬” ({fraud_pct[1]:.3f}%)")
print(f"   - ç±»åˆ«ä¸å¹³è¡¡æ¯”ä¾‹ï¼šçº¦ 1:{fraud_counts[0]/fraud_counts[1]:.0f}")

# åˆ›å»º plot ç›®å½•ç”¨äºå­˜æ”¾å›¾è¡¨
if not os.path.exists('plot'):
    os.makedirs('plot')

# =============================================================================
# ğŸ”§ ç¬¬äºŒæ­¥ï¼šæ•°æ®é¢„å¤„ç†
# =============================================================================

print("=" * 60)
print("âš™ï¸ æ­¥éª¤2ï¼šæ•°æ®é¢„å¤„ç†")
print("=" * 60)

# æ ‡å‡†åŒ– 'Amount' å’Œ 'Time' ç‰¹å¾
scaler = StandardScaler()
data['scaled_amount'] = scaler.fit_transform(data['Amount'].values.reshape(-1, 1))
data['scaled_time'] = scaler.fit_transform(data['Time'].values.reshape(-1, 1))
data = data.drop(['Time', 'Amount'], axis=1)

print("âœ… 'Time' å’Œ 'Amount' ç‰¹å¾å·²æ ‡å‡†åŒ–ã€‚")

# åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡å˜é‡
X = data.drop('Class', axis=1)
y = data['Class']

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nğŸ“Š æ•°æ®é›†åˆ’åˆ†å®Œæ¯•ï¼š")
print(f"   - è®­ç»ƒé›†: {X_train.shape[0]:,} æ ·æœ¬")
print(f"   - æµ‹è¯•é›†: {X_test.shape[0]:,} æ ·æœ¬")


def visualize_class_distribution(data):
    """å¯è§†åŒ–ç›®æ ‡å˜é‡'Class'çš„åˆ†å¸ƒæƒ…å†µ"""
    class_counts = data['Class'].value_counts()
    
    print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆç›®æ ‡å˜é‡åˆ†å¸ƒå›¾...")
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
    
    # ç”œç”œåœˆå›¾
    colors = ['#66b3ff', '#ff9999']
    labels = ['æ­£å¸¸ (Class 0)', 'æ¬ºè¯ˆ (Class 1)']
    ax1.pie(class_counts, labels=labels, autopct='%1.3f%%', 
            colors=colors, startangle=140, wedgeprops=dict(width=0.3), pctdistance=0.85)
    centre_circle = plt.Circle((0,0),0.70,fc='white')
    fig.gca().add_artist(centre_circle)
    ax1.set_title('äº¤æ˜“ç±»åˆ«åˆ†å¸ƒ (ç”œç”œåœˆå›¾)', fontsize=16, fontweight='bold')
    
    # æŸ±çŠ¶å›¾ (ä½¿ç”¨å¯¹æ•°åˆ»åº¦)
    sns.barplot(x=class_counts.index, y=class_counts.values, ax=ax2, palette=colors)
    ax2.set_title('äº¤æ˜“ç±»åˆ«æ•°é‡å¯¹æ¯”', fontsize=16, fontweight='bold')
    ax2.set_xlabel('äº¤æ˜“ç±»åˆ«', fontsize=12)
    ax2.set_ylabel('äº¤æ˜“æ•°é‡ (å¯¹æ•°åˆ»åº¦)', fontsize=12)
    ax2.set_xticks([0, 1])
    ax2.set_xticklabels(labels)
    ax2.set_yscale('log')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, count in enumerate(class_counts.values):
        ax2.text(i, count, f'{count:,}', 
                 ha='center', va='bottom', fontsize=12, fontweight='bold')
        
    plt.tight_layout()
    save_path = 'plot/class_distribution.png'
    plt.savefig(save_path)
    print(f"ğŸ–¼ï¸  ç›®æ ‡å˜é‡åˆ†å¸ƒå›¾å·²ä¿å­˜è‡³ '{save_path}'")
    plt.close() # å…³é—­å›¾åƒï¼Œé¿å…åœ¨è„šæœ¬è¿è¡Œæ—¶æ˜¾ç¤º

# è°ƒç”¨å¯è§†åŒ–å‡½æ•°
visualize_class_distribution(data)

# =============================================================================
# ğŸ¤– ç¬¬ä¸‰æ­¥ï¼šæ¨¡å‹è®­ç»ƒä¸å¯¹æ¯”
# =============================================================================

print("=" * 60)
print("ğŸš€ æ­¥éª¤3ï¼šæ¨¡å‹è®­ç»ƒä¸å¯¹æ¯”")
print("=" * 60)

# å®šä¹‰ä¸€ä¸ªå­—å…¸æ¥å­˜å‚¨æ‰€æœ‰æ¨¡å‹çš„ç»“æœ
results = {}

# --- æ¨¡å‹1ï¼šé€»è¾‘å›å½’ (åŸºçº¿æ¨¡å‹) ---
print("\nâ³ 1. è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹...")
lr_model = LogisticRegression(random_state=42, max_iter=1000)
lr_model.fit(X_train, y_train)
print("âœ… é€»è¾‘å›å½’æ¨¡å‹è®­ç»ƒå®Œæˆã€‚")

# --- æ¨¡å‹2ï¼šXGBoost (æ— ç±»åˆ«æƒé‡ - æ¶ˆèå®éªŒ) ---
print("\nâ³ 2. è®­ç»ƒ XGBoost (æ— æƒé‡)... ")
xgb_no_weight = XGBClassifier(
    objective='binary:logistic',
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)
xgb_no_weight.fit(X_train, y_train)
print("âœ… XGBoost (æ— æƒé‡) æ¨¡å‹è®­ç»ƒå®Œæˆã€‚")

# --- æ¨¡å‹3ï¼šXGBoost (æœ‰ç±»åˆ«æƒé‡) ---
print("\nâ³ 3. è®­ç»ƒ XGBoost (æœ‰æƒé‡)... ")
scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]
print(f"âš–ï¸ ç±»åˆ«æƒé‡ (scale_pos_weight): {scale_pos_weight:.2f}")
xgb_model = XGBClassifier(
    objective='binary:logistic',
    scale_pos_weight=scale_pos_weight,
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)
xgb_model.fit(X_train, y_train)
print("âœ… XGBoost (æœ‰æƒé‡) æ¨¡å‹è®­ç»ƒå®Œæˆã€‚")

# =============================================================================
# ğŸ“ˆ ç¬¬å››æ­¥ï¼šæ¨¡å‹è¯„ä¼°ä¸å¯¹æ¯”
# =============================================================================

print("=" * 60)
print("ğŸ“Š æ­¥éª¤4ï¼šæ¨¡å‹æ€§èƒ½è¯„ä¼°ä¸å¯¹æ¯”")
print("=" * 60)

# è¯„ä¼°å‡½æ•°
def evaluate_model(model, X_test, y_test, model_name):
    predictions = model.predict(X_test)
    # å¯¹äºé€»è¾‘å›å½’å’ŒXGBoostï¼Œæˆ‘ä»¬å…³å¿ƒæ¦‚ç‡
    if hasattr(model, "predict_proba"):
        probas = model.predict_proba(X_test)[:, 1]
        roc_auc = roc_auc_score(y_test, probas)
        auprc = average_precision_score(y_test, probas)
    else: # å¯¹äºIsolation Forest
        # decision_functionè¿”å›å¼‚å¸¸åˆ†æ•°ï¼Œåˆ†æ•°è¶Šä½è¶Šå¼‚å¸¸
        scores = model.decision_function(X_test)
        # å°†åˆ†æ•°è½¬æ¢ä¸ºç±»ä¼¼æ¦‚ç‡çš„åº¦é‡ï¼ˆè¶Šå°è¶Šå¯èƒ½æ˜¯æ¬ºè¯ˆï¼‰
        probas = -scores
        roc_auc = roc_auc_score(y_test, probas)
        auprc = average_precision_score(y_test, probas)

    report = classification_report(y_test, predictions, target_names=['æ­£å¸¸', 'æ¬ºè¯ˆ'], output_dict=True)
    
    results[model_name] = {
        'ROC AUC': roc_auc,
        'AUPRC': auprc,
        'Precision (Fraud)': report['æ¬ºè¯ˆ']['precision'],
        'Recall (Fraud)': report['æ¬ºè¯ˆ']['recall'],
        'F1-score (Fraud)': report['æ¬ºè¯ˆ']['f1-score']
    }
    
    print(f"\n--- è¯„ä¼°: {model_name} ---")
    print(classification_report(y_test, predictions, target_names=['æ­£å¸¸', 'æ¬ºè¯ˆ']))
    print(f"ROC AUC: {roc_auc:.4f}")
    print(f"AUPRC: {auprc:.4f}")
    
    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_test, predictions)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['æ­£å¸¸', 'æ¬ºè¯ˆ'], yticklabels=['æ­£å¸¸', 'æ¬ºè¯ˆ'])
    plt.title(f'{model_name} æ··æ·†çŸ©é˜µ', fontsize=16)
    plt.xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)
    plt.ylabel('çœŸå®æ ‡ç­¾', fontsize=12)
    file_name = f"plot/{model_name.replace(' ', '_').lower()}_confusion_matrix.png"
    plt.savefig(file_name)
    print(f"ğŸ–¼ï¸  æ··æ·†çŸ©é˜µå·²ä¿å­˜ä¸º '{file_name}'")
    plt.close()
    return probas

# è¯„ä¼°æ‰€æœ‰ç›‘ç£æ¨¡å‹
probas_lr = evaluate_model(lr_model, X_test, y_test, 'Logistic Regression')
probas_xgb_no_weight = evaluate_model(xgb_no_weight, X_test, y_test, 'XGBoost No Weight')
probas_xgb = evaluate_model(xgb_model, X_test, y_test, 'XGBoost With Weight')

# ç»˜åˆ¶ Precision-Recall æ›²çº¿å¯¹æ¯”
plt.figure(figsize=(10, 8))

precision, recall, _ = precision_recall_curve(y_test, probas_lr)
plt.plot(recall, precision, marker='.', label='Logistic Regression')

precision, recall, _ = precision_recall_curve(y_test, probas_xgb_no_weight)
plt.plot(recall, precision, marker='.', label='XGBoost No Weight')

precision, recall, _ = precision_recall_curve(y_test, probas_xgb)
plt.plot(recall, precision, marker='.', label='XGBoost With Weight')

plt.xlabel('å¬å›ç‡ (Recall)')
plt.ylabel('ç²¾ç¡®ç‡ (Precision)')
plt.title('æ¨¡å‹ Precision-Recall æ›²çº¿å¯¹æ¯”')
plt.legend()
plt.grid(True)
plt.savefig('plot/precision_recall_curve_comparison.png')
print("\nğŸ–¼ï¸  Precision-Recall æ›²çº¿å¯¹æ¯”å›¾å·²ä¿å­˜ä¸º 'plot/precision_recall_curve_comparison.png'")
plt.close()

# =============================================================================
# ğŸŒ² ç¬¬äº”æ­¥ï¼šæ¨¡å‹è®­ç»ƒ - Isolation Forest (æ— ç›‘ç£)
# =============================================================================

print("=" * 60)
print("ğŸŒ² æ­¥éª¤5ï¼šä½¿ç”¨ Isolation Forest è¿›è¡Œæ— ç›‘ç£å¼‚å¸¸æ£€æµ‹")
print("=" * 60)

# contamination å‚æ•°è®¾ç½®ä¸ºæ•°æ®é›†ä¸­å·²çŸ¥çš„æ¬ºè¯ˆç‡
contamination_rate = float(fraud_pct[1] / 100)

iso_forest = IsolationForest(
    n_estimators=100,
    contamination=contamination_rate,
    random_state=42,
    n_jobs=-1
)

print("\nâ³ å¼€å§‹è®­ç»ƒ Isolation Forest æ¨¡å‹...")
iso_forest.fit(X_train)
print("âœ… Isolation Forest æ¨¡å‹è®­ç»ƒå®Œæˆã€‚")

# è¯„ä¼° Isolation Forest
iso_preds_binary = [1 if p == -1 else 0 for p in iso_forest.predict(X_test)]

# å¯¹äºæ— ç›‘ç£æ¨¡å‹ï¼Œæˆ‘ä»¬å•ç‹¬è¯„ä¼°å¹¶æ·»åŠ åˆ°ç»“æœä¸­
report_iso = classification_report(y_test, iso_preds_binary, target_names=['æ­£å¸¸', 'æ¬ºè¯ˆ'], output_dict=True)
scores_iso = -iso_forest.decision_function(X_test)
roc_auc_iso = roc_auc_score(y_test, scores_iso)
auprc_iso = average_precision_score(y_test, scores_iso)

results['Isolation Forest'] = {
    'ROC AUC': roc_auc_iso,
    'AUPRC': auprc_iso,
    'Precision (Fraud)': report_iso['æ¬ºè¯ˆ']['precision'],
    'Recall (Fraud)': report_iso['æ¬ºè¯ˆ']['recall'],
    'F1-score (Fraud)': report_iso['æ¬ºè¯ˆ']['f1-score']
}

print("\n--- è¯„ä¼°: Isolation Forest ---")
print(classification_report(y_test, iso_preds_binary, target_names=['æ­£å¸¸', 'æ¬ºè¯ˆ']))
print(f"ROC AUC: {roc_auc_iso:.4f}")
print(f"AUPRC: {auprc_iso:.4f}")

cm_iso = confusion_matrix(y_test, iso_preds_binary)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_iso, annot=True, fmt='d', cmap='Greens', 
            xticklabels=['æ­£å¸¸', 'æ¬ºè¯ˆ'], yticklabels=['æ­£å¸¸', 'æ¬ºè¯ˆ'])
plt.title('Isolation Forest æ··æ·†çŸ©é˜µ', fontsize=16)
plt.xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)
plt.ylabel('çœŸå®æ ‡ç­¾', fontsize=12)
plt.savefig('plot/isolation_forest_confusion_matrix.png')
print("ğŸ–¼ï¸  Isolation Forest æ··æ·†çŸ©é˜µå·²ä¿å­˜ä¸º 'plot/isolation_forest_confusion_matrix.png'")
plt.close()

# =============================================================================
# ğŸ† ç¬¬å…­æ­¥ï¼šç»“æœæ±‡æ€»ä¸å¯¹æ¯”
# =============================================================================

print("=" * 60)
print("ğŸ† æ­¥éª¤6ï¼šæ‰€æœ‰æ¨¡å‹æ€§èƒ½æ±‡æ€»")
print("=" * 60)

results_df = pd.DataFrame(results).T.sort_values(by='AUPRC', ascending=False)

print(results_df.to_markdown())

print("\nğŸ‰ å®æˆ˜å®Œæˆï¼è¯·æŸ¥çœ‹ç”Ÿæˆçš„å›¾ç‰‡ã€è¯„ä¼°æŠ¥å‘Šå’Œæœ€ç»ˆçš„æ€§èƒ½å¯¹æ¯”è¡¨ã€‚")